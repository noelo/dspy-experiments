{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc5bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import dspy \n",
    "import os\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.getLogger(\"LiteLLM\").setLevel(logging.WARN)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARN)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARN)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"dspy\").setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://mlflow:8080/\")\n",
    "mlflow.set_experiment(\"deploy_dspy_program\")\n",
    "mlflow.dspy.autolog(\n",
    "    log_compiles=True,    # Track optimization process\n",
    "    log_evals=True,       # Track evaluation results\n",
    "    log_traces_from_compile=True  # Track program traces during optimization\n",
    ")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9928bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_URL=os.getenv('LLM_URL')\n",
    "API_KEY=os.getenv('API_KEY')\n",
    "LLM_MODEL=os.getenv('LLM_MODEL')\n",
    "dspy.enable_logging()\n",
    "lm = dspy.LM(LLM_MODEL,\n",
    "             api_base=LLM_URL,  # ensure this points to your port\n",
    "             api_key=API_KEY, model_type='chat')\n",
    "dspy.configure(lm=lm)\n",
    "dspy.settings.configure(track_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79c5f158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='When two dice are tossed, each die has 6 faces, numbered from 1 to 6. The total number of possible outcomes when two dice are rolled is \\\\(6 \\\\times 6 = 36\\\\).\\n\\nTo find the probability that the sum of the numbers on the two dice equals 2, we need to determine how many outcomes result in this sum. The only way to achieve a sum of 2 is if both dice show a 1. Therefore, there is only 1 favorable outcome: (1, 1).\\n\\nThe probability of an event is calculated as the number of favorable outcomes divided by the total number of possible outcomes. Thus, the probability that the sum equals 2 is:\\n\\n\\\\[\\n\\\\frac{\\\\text{Number of favorable outcomes}}{\\\\text{Total number of possible outcomes}} = \\\\frac{1}{36}\\n\\\\]\\n\\nConverting this fraction to a float gives us approximately 0.027777777777777776.',\n",
      "    answer=0.027777777777777776\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://mlflow:8080/static-files/lib/notebook-trace-renderer/index.html?trace_id=21aa0aeeb9394e80bcc098580cf03823&amp;experiment_id=1&amp;version=2.22.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(request_id=21aa0aeeb9394e80bcc098580cf03823)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "math = dspy.ChainOfThought(\"question -> answer: float\")\n",
    "x=math(question=\"Two dice are tossed. What is the probability that the sum equals two?\")\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84362aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.get_lm_usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11e7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_math(expression: str):\n",
    "    return dspy.PythonInterpreter({}).execute(expression)\n",
    "\n",
    "def search_wikipedia(query: str):\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=3)\n",
    "    return [x['text'] for x in results]\n",
    "\n",
    "react = dspy.ReAct(\"question -> answer: float\", tools=[evaluate_math, search_wikipedia])\n",
    "\n",
    "pred = react(question=\"What is 9362158 divided by the year of birth of David Gregory of Kinnairdy castle?\")\n",
    "print(pred.answer)\n",
    "dspy.inspect_history(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3620720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Outline(dspy.Signature):\n",
    "    \"\"\"Outline a thorough overview of a topic.\"\"\"\n",
    "\n",
    "    topic: str = dspy.InputField()\n",
    "    title: str = dspy.OutputField()\n",
    "    sections: list[str] = dspy.OutputField()\n",
    "    section_subheadings: dict[str, list[str]] = dspy.OutputField(desc=\"mapping from section headings to subheadings\")\n",
    "\n",
    "class DraftSection(dspy.Signature):\n",
    "    \"\"\"Draft a top-level section of an article.\"\"\"\n",
    "\n",
    "    topic: str = dspy.InputField()\n",
    "    section_heading: str = dspy.InputField()\n",
    "    section_subheadings: list[str] = dspy.InputField()\n",
    "    content: str = dspy.OutputField(desc=\"markdown-formatted section\")\n",
    "\n",
    "class DraftArticle(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.build_outline = dspy.ChainOfThought(Outline)\n",
    "        self.draft_section = dspy.ChainOfThought(DraftSection)\n",
    "\n",
    "    def forward(self, topic):\n",
    "        outline = self.build_outline(topic=topic)\n",
    "        sections = []\n",
    "        for heading, subheadings in outline.section_subheadings.items():\n",
    "            section, subheadings = f\"## {heading}\", [f\"### {subheading}\" for subheading in subheadings]\n",
    "            section = self.draft_section(topic=outline.title, section_heading=section, section_subheadings=subheadings)\n",
    "            sections.append(section.content)\n",
    "        return dspy.Prediction(title=outline.title, sections=sections)\n",
    "\n",
    "draft_article = DraftArticle()\n",
    "article = draft_article(topic=\"World War 2\")\n",
    "print(article.get_lm_usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63658023",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.inspect_history(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494ff232",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b411c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractInfo(dspy.Signature):\n",
    "    \"\"\"Extract structured information from text.\"\"\"\n",
    "\n",
    "    text: str = dspy.InputField()\n",
    "    title: str = dspy.OutputField()\n",
    "    headings: list[str] = dspy.OutputField()\n",
    "    entities: list[dict[str, str]] = dspy.OutputField(desc=\"a list of entities and their metadata\")\n",
    "\n",
    "module = dspy.Predict(ExtractInfo)\n",
    "\n",
    "text = \"Apple Inc. announced its latest iPhone 14 today.\" \\\n",
    "    \"The CEO, Tim Cook, highlighted its new features in a press release.\"\n",
    "response = module(text=text)\n",
    "\n",
    "print(response.title)\n",
    "print(response.headings)\n",
    "print(response.entities)\n",
    "dspy.inspect_history(n=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(query: str) -> list[str]:\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=3)\n",
    "    return [x['text'] for x in results]\n",
    "\n",
    "rag = dspy.ChainOfThought('context, question -> response')\n",
    "\n",
    "question = \"What's the name of the castle that David Gregory inherited?\"\n",
    "rag(context=search_wikipedia(question), question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe0bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.inspect_history(n=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a35664",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckCitationFaithfulness(dspy.Signature):\n",
    "    \"\"\"Verify that the text is based on the provided context.\"\"\"\n",
    "\n",
    "    context: str = dspy.InputField(desc=\"facts here are assumed to be true\")\n",
    "    text: str = dspy.InputField()\n",
    "    faithfulness: bool = dspy.OutputField()\n",
    "    evidence: dict[str, list[str]] = dspy.OutputField(desc=\"Supporting evidence for claims\")\n",
    "\n",
    "context = \"The 21-year-old made seven appearances for the Hammers and netted his only goal for them in a Europa League qualification round match against Andorran side FC Lustrains last season. Lee had two loan spells in League One last term, with Blackpool and then Colchester United. He scored twice for the U's but was unable to save them from relegation. The length of Lee's contract with the promoted Tykes has not been revealed. Find all the latest football transfers on our dedicated page.\"\n",
    "\n",
    "text = \"Lee scored 3 goals for Colchester United.\"\n",
    "\n",
    "faithfulness = dspy.ChainOfThought(CheckCitationFaithfulness)\n",
    "faithfulness(context=context, text=text)\n",
    "dspy.inspect_history(n=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What's something great about the ColBERT retrieval model?\"\n",
    "\n",
    "# 1) Declare with a signature, and pass some config.\n",
    "classify = dspy.ChainOfThought('question -> answer', n=5)\n",
    "\n",
    "# 2) Call with input argument.\n",
    "response = classify(question=question)\n",
    "\n",
    "# 3) Access the outputs.\n",
    "response.completions.answer\n",
    "\n",
    "dspy.inspect_history(n=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89f27d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:47:23 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '58b2ce787aa841168c3645a190bc40fe', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current dspy workflow\n",
      "2025/06/02 09:47:23 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 20\n",
      "minibatch: False\n",
      "num_fewshot_candidates: 6\n",
      "num_instruct_candidates: 3\n",
      "valset size: 40\n",
      "\n",
      "2025/06/02 09:47:23 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/06/02 09:47:23 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/06/02 09:47:23 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=6 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/6\n",
      "Bootstrapping set 2/6\n",
      "Bootstrapping set 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 9 examples for up to 1 rounds, amounting to 10 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.28it/s]\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:05<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 9 examples for up to 1 rounds, amounting to 9 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.94it/s]\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:03<00:03,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.32it/s]\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:03<00:02,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.90it/s]\n",
      "2025/06/02 09:47:48 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/06/02 09:47:48 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
      "2025/06/02 09:47:49 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=3 instructions...\n",
      "\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "You are an Agent. In each episode, you will be given the fields `question` as input. And you can see your past trajectory so far.\n",
      "Your goal is to use one or more of the supplied tools to collect any necessary information for producing `answer`.\n",
      "\n",
      "To do this, you will interleave next_thought, next_tool_name, and next_tool_args in each turn, and also when finishing the task.\n",
      "After each tool call, you receive a resulting observation, which gets appended to your trajectory.\n",
      "\n",
      "When writing next_thought, you may reason about the current situation and plan for future steps.\n",
      "When selecting the next_tool_name and its next_tool_args, the tool must be one of:\n",
      "\n",
      "(1) search, whose description is <desc>Retrieves abstracts from Wikipedia.</desc>. It takes arguments {'query': {'type': 'string'}} in JSON format.\n",
      "(2) finish, whose description is <desc>Marks the task as complete. That is, signals that all information for producing the outputs, i.e. `answer`, are now available to be extracted.</desc>. It takes arguments {} in JSON format.\n",
      "\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "You are an Agent. In each episode, you will be given the fields `question` as input. You will also have access to your past trajectory, allowing you to build upon previous actions and observations.\n",
      "\n",
      "Your goal is to use one or more of the supplied tools to gather the necessary information for producing an accurate `answer`.\n",
      "\n",
      "To achieve this, you will interleave `next_thought`, `next_tool_name`, and `next_tool_args` in each turn, and also when concluding the task. After each tool call, you will receive an observation, which will be added to your trajectory.\n",
      "\n",
      "When crafting `next_thought`, you may analyze the current situation and devise a plan for future actions. When selecting the `next_tool_name` and its `next_tool_args`, ensure the tool is one of:\n",
      "\n",
      "1. `search`, which retrieves abstracts from Wikipedia. It requires arguments in the format `{'query': {'type': 'string'}}`.\n",
      "2. `finish`, which marks the task as complete, indicating that all necessary information for producing the `answer` has been gathered. It requires no arguments.\n",
      "\n",
      "Remember, you can creatively plan your steps to efficiently gather information and reach a conclusion.\n",
      "\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: 2: To effectively solve the task of answering questions using the ReAct framework, follow this structured approach:\n",
      "\n",
      "1. **Understand the Question**: Begin by carefully analyzing the question to identify the key information needed to provide an answer.\n",
      "\n",
      "2. **Plan Your Approach**: Formulate a `next_thought` that outlines your reasoning process. Consider what information is missing and how it can be obtained using the available tools.\n",
      "\n",
      "3. **Select the Appropriate Tool**:\n",
      "   - Use the `search` tool to retrieve relevant information from Wikipedia. Specify your query clearly in `next_tool_args`.\n",
      "   - If you have gathered all necessary information, use the `finish` tool to indicate that the task is complete.\n",
      "\n",
      "4. **Iterate and Update**:\n",
      "   - After each tool call, update your trajectory with the `next_thought`, `next_tool_name`, `next_tool_args`, and the resulting `observation`.\n",
      "   - Use the information from the observation to refine your reasoning and decide on the next steps.\n",
      "\n",
      "5. **Conclude the Task**:\n",
      "   - Once you have all the required information, use the `finish` tool to signal completion.\n",
      "   - Extract the answer from the gathered information.\n",
      "\n",
      "6. **Example Execution**:\n",
      "   - For a question about a film studio, search for each film individually to find their respective studios, then compare the results.\n",
      "   - For a question about music sales, identify the relevant song and search for its sales figures.\n",
      "\n",
      "By following these steps, you can systematically gather and synthesize information to produce accurate answers. Ensure that each step is clearly documented in your trajectory for clarity and future reference.\n",
      "\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 1:\n",
      "\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Given the fields `question`, produce the fields `answer`. You are an Agent tasked with solving a critical inquiry that demands precise and accurate information retrieval. Your mission is to navigate through a series of strategic decisions, leveraging the available tools to gather necessary data. The success of this task is paramount, as it will determine the accuracy and reliability of the final answer. \n",
      "\n",
      "You will interleave next_thought, next_tool_name, and next_tool_args in each turn, and also when finishing the task. After each tool call, you receive a resulting observation, which gets appended to your trajectory. When writing next_thought, reason about the current situation and plan for future steps. When selecting the next_tool_name and its next_tool_args, ensure the tool is one of:\n",
      "\n",
      "1. **search**: Retrieves abstracts from Wikipedia. It takes arguments {'query': {'type': 'string'}} in JSON format.\n",
      "2. **finish**: Marks the task as complete, signaling that all information for producing the outputs, i.e., `answer`, are now available to be extracted. It takes arguments {} in JSON format.\n",
      "\n",
      "Your goal is to use one or more of the supplied tools to collect any necessary information for producing `answer`. The trajectory, which records all thoughts, tool selections, tool arguments, and observations, is crucial for extracting the final answer. Ensure that each step is meticulously planned and executed to achieve the most accurate and comprehensive response possible.\n",
      "\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Given a `question` and a `trajectory` of past actions and observations, use the `Predict` module to generate the fields `reasoning`, `answer`, `next_thought`, `next_tool_name`, and `next_tool_args`. The module should interleave thoughts and actions to gather necessary information and produce a reasoned answer. Use the tools `search` to retrieve information and `finish` to mark the task as complete. Ensure that the reasoning process is clear and logical, and that the final answer is derived from the gathered information.\n",
      "\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/06/02 09:47:58 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 20 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 40 (20.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:07<00:00,  5.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:48:06 INFO dspy.evaluate.evaluate: Average Metric: 8 / 40 (20.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_0 at: http://mlflow:8080/#/experiments/34/runs/acac789193cf4da2a0bbe3801e6eab24\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:48:06 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 20.0\n",
      "\n",
      "/home/noelo/.pyenv/versions/3.11.11/envs/dspy/lib/python3.11/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/06/02 09:48:06 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 40 (10.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:08<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:48:16 INFO dspy.evaluate.evaluate: Average Metric: 4 / 40 (10.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_1 at: http://mlflow:8080/#/experiments/34/runs/5e52dee93bfd4730934e95eae486140f\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:48:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 10.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 0'].\n",
      "2025/06/02 09:48:16 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0]\n",
      "2025/06/02 09:48:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 20.0\n",
      "2025/06/02 09:48:16 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 09:48:16 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 40 (37.5%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:09<00:00,  4.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:48:26 INFO dspy.evaluate.evaluate: Average Metric: 15 / 40 (37.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_2 at: http://mlflow:8080/#/experiments/34/runs/14bc367257134a3cbcb33b152bee62bd\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:48:27 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 37.5\n",
      "2025/06/02 09:48:27 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 37.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 2'].\n",
      "2025/06/02 09:48:27 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5]\n",
      "2025/06/02 09:48:27 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 37.5\n",
      "2025/06/02 09:48:27 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 09:48:27 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 40 (10.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:08<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:48:36 INFO dspy.evaluate.evaluate: Average Metric: 4 / 40 (10.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_3 at: http://mlflow:8080/#/experiments/34/runs/4a2b51711c074e378237ad45b407bd85\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:48:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 10.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 0'].\n",
      "2025/06/02 09:48:36 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0]\n",
      "2025/06/02 09:48:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 37.5\n",
      "2025/06/02 09:48:36 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 09:48:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 40 (35.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:09<00:00,  4.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:48:47 INFO dspy.evaluate.evaluate: Average Metric: 14 / 40 (35.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_4 at: http://mlflow:8080/#/experiments/34/runs/57568a2da1354b709104f44c113075c0\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:48:47 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 35.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 4'].\n",
      "2025/06/02 09:48:47 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0]\n",
      "2025/06/02 09:48:47 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 37.5\n",
      "2025/06/02 09:48:47 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 09:48:47 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 40 (37.5%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:08<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:48:56 INFO dspy.evaluate.evaluate: Average Metric: 15 / 40 (37.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_5 at: http://mlflow:8080/#/experiments/34/runs/b8a493064a9744659103b269f59cfb6b\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:48:57 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 37.5 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 2'].\n",
      "2025/06/02 09:48:57 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5]\n",
      "2025/06/02 09:48:57 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 37.5\n",
      "2025/06/02 09:48:57 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 09:48:57 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 40 (25.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:08<00:00,  4.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:49:06 INFO dspy.evaluate.evaluate: Average Metric: 10 / 40 (25.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_6 at: http://mlflow:8080/#/experiments/34/runs/9e2eff88c3364e498454f0e3823c91aa\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:49:06 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 25.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 0'].\n",
      "2025/06/02 09:49:06 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0]\n",
      "2025/06/02 09:49:06 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 37.5\n",
      "2025/06/02 09:49:06 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 09:49:06 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 40 (32.5%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:49:18 INFO dspy.evaluate.evaluate: Average Metric: 13 / 40 (32.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_7 at: http://mlflow:8080/#/experiments/34/runs/996a4983320349c8974dab1a65aa228d\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:49:18 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 32.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 2', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 1'].\n",
      "2025/06/02 09:49:18 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5]\n",
      "2025/06/02 09:49:18 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 37.5\n",
      "2025/06/02 09:49:18 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 09:49:18 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 40 (20.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:07<00:00,  5.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:49:26 INFO dspy.evaluate.evaluate: Average Metric: 8 / 40 (20.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_8 at: http://mlflow:8080/#/experiments/34/runs/927c4786234249629ce49fbbcd581ef8\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:49:27 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 20.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 0'].\n",
      "2025/06/02 09:49:27 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0]\n",
      "2025/06/02 09:49:27 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 37.5\n",
      "2025/06/02 09:49:27 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 09:49:27 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 40 (35.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:07<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:49:35 INFO dspy.evaluate.evaluate: Average Metric: 14 / 40 (35.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_9 at: http://mlflow:8080/#/experiments/34/runs/abf540b1d04f48cbb0885273f117685a\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:49:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 35.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 4'].\n",
      "2025/06/02 09:49:36 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0, 35.0]\n",
      "2025/06/02 09:49:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 37.5\n",
      "2025/06/02 09:49:36 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 09:49:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 40 (42.5%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:09<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:49:46 INFO dspy.evaluate.evaluate: Average Metric: 17 / 40 (42.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_10 at: http://mlflow:8080/#/experiments/34/runs/2718751c881747718c15dffff4cced6f\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:49:47 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 42.5\n",
      "2025/06/02 09:49:47 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 2'].\n",
      "2025/06/02 09:49:47 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0, 35.0, 42.5]\n",
      "2025/06/02 09:49:47 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.5\n",
      "2025/06/02 09:49:47 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 09:49:47 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 12 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 40 (42.5%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:08<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:49:56 INFO dspy.evaluate.evaluate: Average Metric: 17 / 40 (42.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_11 at: http://mlflow:8080/#/experiments/34/runs/404c3bdbad0b4f83814576b9038929d7\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:49:57 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 3'].\n",
      "2025/06/02 09:49:57 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0, 35.0, 42.5, 42.5]\n",
      "2025/06/02 09:49:57 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.5\n",
      "2025/06/02 09:49:57 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 09:49:57 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 40 (42.5%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:09<00:00,  4.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:50:07 INFO dspy.evaluate.evaluate: Average Metric: 17 / 40 (42.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_12 at: http://mlflow:8080/#/experiments/34/runs/168629492c3743bda437451cfdbea958\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:50:08 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 3'].\n",
      "2025/06/02 09:50:08 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0, 35.0, 42.5, 42.5, 42.5]\n",
      "2025/06/02 09:50:08 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.5\n",
      "2025/06/02 09:50:08 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 09:50:08 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 14 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 40 (42.5%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:08<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:50:17 INFO dspy.evaluate.evaluate: Average Metric: 17 / 40 (42.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_13 at: http://mlflow:8080/#/experiments/34/runs/68757a88e9d6418d8dee0c5831475c28\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:50:17 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 2'].\n",
      "2025/06/02 09:50:17 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0, 35.0, 42.5, 42.5, 42.5, 42.5]\n",
      "2025/06/02 09:50:17 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.5\n",
      "2025/06/02 09:50:17 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 09:50:17 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 15 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 40 (40.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:08<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:50:26 INFO dspy.evaluate.evaluate: Average Metric: 16 / 40 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_14 at: http://mlflow:8080/#/experiments/34/runs/4dd2fcf5a4464304a359d5e82e77aaa5\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:50:27 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 40.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 1', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 5'].\n",
      "2025/06/02 09:50:27 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0, 35.0, 42.5, 42.5, 42.5, 42.5, 40.0]\n",
      "2025/06/02 09:50:27 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.5\n",
      "2025/06/02 09:50:27 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 09:50:27 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 16 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 40 (5.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:08<00:00,  4.59it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:50:36 INFO dspy.evaluate.evaluate: Average Metric: 2 / 40 (5.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_15 at: http://mlflow:8080/#/experiments/34/runs/f6d97cdf9b5b402abc733c7c17adc152\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:50:37 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 5.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 0'].\n",
      "2025/06/02 09:50:37 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0, 35.0, 42.5, 42.5, 42.5, 42.5, 40.0, 5.0]\n",
      "2025/06/02 09:50:37 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.5\n",
      "2025/06/02 09:50:37 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 09:50:37 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 17 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 40 (40.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:09<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:50:47 INFO dspy.evaluate.evaluate: Average Metric: 16 / 40 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_16 at: http://mlflow:8080/#/experiments/34/runs/a967adf1a3ab487fa5bf93d229af0bb3\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:50:48 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 40.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 5'].\n",
      "2025/06/02 09:50:48 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0, 35.0, 42.5, 42.5, 42.5, 42.5, 40.0, 5.0, 40.0]\n",
      "2025/06/02 09:50:48 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.5\n",
      "2025/06/02 09:50:48 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 09:50:48 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 18 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 40 (42.5%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:10<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:50:59 INFO dspy.evaluate.evaluate: Average Metric: 17 / 40 (42.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_17 at: http://mlflow:8080/#/experiments/34/runs/2c960556daed466cad0758978a846050\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:50:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 4'].\n",
      "2025/06/02 09:50:59 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0, 35.0, 42.5, 42.5, 42.5, 42.5, 40.0, 5.0, 40.0, 42.5]\n",
      "2025/06/02 09:50:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.5\n",
      "2025/06/02 09:50:59 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 09:50:59 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 40 (40.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:09<00:00,  4.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:51:09 INFO dspy.evaluate.evaluate: Average Metric: 16 / 40 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_18 at: http://mlflow:8080/#/experiments/34/runs/f5cc33761fe14c91ac190908e8e4ff38\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:51:10 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 40.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 1'].\n",
      "2025/06/02 09:51:10 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0, 35.0, 42.5, 42.5, 42.5, 42.5, 40.0, 5.0, 40.0, 42.5, 40.0]\n",
      "2025/06/02 09:51:10 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.5\n",
      "2025/06/02 09:51:10 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 09:51:10 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 20 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 40 (2.5%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:08<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:51:20 INFO dspy.evaluate.evaluate: Average Metric: 1 / 40 (2.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_19 at: http://mlflow:8080/#/experiments/34/runs/acba27b579bc4cd48c69e4e40cf2459b\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:51:20 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 2.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 0'].\n",
      "2025/06/02 09:51:20 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0, 35.0, 42.5, 42.5, 42.5, 42.5, 40.0, 5.0, 40.0, 42.5, 40.0, 2.5]\n",
      "2025/06/02 09:51:20 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.5\n",
      "2025/06/02 09:51:20 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 09:51:20 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 21 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 40 (37.5%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:10<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:51:31 INFO dspy.evaluate.evaluate: Average Metric: 15 / 40 (37.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸƒ View run eval_full_20 at: http://mlflow:8080/#/experiments/34/runs/2c9acc44e7d348a7a7f830e55331ea65\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 09:51:32 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 37.5 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 3', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 3'].\n",
      "2025/06/02 09:51:32 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 10.0, 37.5, 10.0, 35.0, 37.5, 25.0, 32.5, 20.0, 35.0, 42.5, 42.5, 42.5, 42.5, 40.0, 5.0, 40.0, 42.5, 40.0, 2.5, 37.5]\n",
      "2025/06/02 09:51:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.5\n",
      "2025/06/02 09:51:32 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 09:51:32 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 42.5!\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run funny-donkey-48 at: http://mlflow:8080/#/experiments/34/runs/58b2ce787aa841168c3645a190bc40fe\n",
      "ðŸ§ª View experiment at: http://mlflow:8080/#/experiments/34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://mlflow:8080/static-files/lib/notebook-trace-renderer/index.html?trace_id=440697b656b64ee8a670a6c2bb72a395&amp;experiment_id=34&amp;trace_id=021d9e9beaca4135b2295b767aecba4a&amp;experiment_id=34&amp;trace_id=f43feb34d5604c238f1cce7ad2faed2b&amp;experiment_id=34&amp;trace_id=950b2122b7db4409b6789fdc88905497&amp;experiment_id=34&amp;trace_id=57038f891d47470992283639f5405c5b&amp;experiment_id=34&amp;trace_id=65a4ba577f4e47aab575fc3c844cba98&amp;experiment_id=34&amp;trace_id=1e5f28f9c30f4397a6c8ca74c3a6c66b&amp;experiment_id=34&amp;trace_id=c98a00969d034fdb8935346977854090&amp;experiment_id=34&amp;trace_id=dd82d64188b34868bb5044511fc93fef&amp;experiment_id=34&amp;trace_id=3acaa9618f8c424ca39ffbc32928dfe4&amp;experiment_id=34&amp;version=2.22.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(request_id=440697b656b64ee8a670a6c2bb72a395), Trace(request_id=021d9e9beaca4135b2295b767aecba4a), Trace(request_id=f43feb34d5604c238f1cce7ad2faed2b), Trace(request_id=950b2122b7db4409b6789fdc88905497), Trace(request_id=57038f891d47470992283639f5405c5b), Trace(request_id=65a4ba577f4e47aab575fc3c844cba98), Trace(request_id=1e5f28f9c30f4397a6c8ca74c3a6c66b), Trace(request_id=c98a00969d034fdb8935346977854090), Trace(request_id=dd82d64188b34868bb5044511fc93fef), Trace(request_id=3acaa9618f8c424ca39ffbc32928dfe4)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.datasets import HotPotQA\n",
    "\n",
    "# logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "# logging.getLogger(\"dspy\").setLevel(logging.DEBUG)\n",
    "\n",
    "# root = logging.getLogger()\n",
    "# root.setLevel(logging.DEBUG)\n",
    "# handler = logging.StreamHandler(sys.stdout)\n",
    "# handler.setLevel(logging.DEBUG)\n",
    "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# handler.setFormatter(formatter)\n",
    "# root.addHandler(handler)\n",
    "\n",
    "mlflow.set_experiment(\"optimized_react\")\n",
    "\n",
    "def search(query: str) -> list[str]:\n",
    "    \"\"\"Retrieves abstracts from Wikipedia.\"\"\"\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=3)\n",
    "    return [x['text'] for x in results]\n",
    "\n",
    "trainset = [x.with_inputs('question') for x in HotPotQA(train_seed=2024, train_size=50).train]\n",
    "react = dspy.ReAct(\"question -> answer\", tools=[search])\n",
    "\n",
    "tp = dspy.MIPROv2(metric=dspy.evaluate.answer_exact_match, auto=\"light\", num_threads=24)\n",
    "optimized_react = tp.compile(react, trainset=trainset,requires_permission_to_run=False)\n",
    "\n",
    "optimized_react.save(path=\"/home/noelo/dev/dspy-poc/optimized_react.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2bdaa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "react = Predict(StringSignature(question, trajectory -> next_thought, next_tool_name, next_tool_args\n",
      "    instructions=\"Given the fields `question`, produce the fields `answer`.\\n\\nYou are an Agent. In each episode, you will be given the fields `question` as input. You will also have access to your past trajectory, allowing you to build upon previous actions and observations.\\n\\nYour goal is to use one or more of the supplied tools to gather the necessary information for producing an accurate `answer`.\\n\\nTo achieve this, you will interleave `next_thought`, `next_tool_name`, and `next_tool_args` in each turn, and also when concluding the task. After each tool call, you will receive an observation, which will be added to your trajectory.\\n\\nWhen crafting `next_thought`, you may analyze the current situation and devise a plan for future actions. When selecting the `next_tool_name` and its `next_tool_args`, ensure the tool is one of:\\n\\n1. `search`, which retrieves abstracts from Wikipedia. It requires arguments in the format `{'query': {'type': 'string'}}`.\\n2. `finish`, which marks the task as complete, indicating that all necessary information for producing the `answer` has been gathered. It requires no arguments.\\n\\nRemember, you can creatively plan your steps to efficiently gather information and reach a conclusion.\"\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    next_thought = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Thought:', 'desc': '${next_thought}'})\n",
      "    next_tool_name = Field(annotation=Literal['search', 'finish'] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Name:', 'desc': '${next_tool_name}'})\n",
      "    next_tool_args = Field(annotation=dict[str, Any] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Args:', 'desc': '${next_tool_args}'})\n",
      "))\n",
      "extract.predict = Predict(StringSignature(question, trajectory -> reasoning, answer\n",
      "    instructions=\"Given the fields `question`, produce the fields `answer`. You are an Agent tasked with solving a critical inquiry that demands precise and accurate information retrieval. Your mission is to navigate through a series of strategic decisions, leveraging the available tools to gather necessary data. The success of this task is paramount, as it will determine the accuracy and reliability of the final answer. \\n\\nYou will interleave next_thought, next_tool_name, and next_tool_args in each turn, and also when finishing the task. After each tool call, you receive a resulting observation, which gets appended to your trajectory. When writing next_thought, reason about the current situation and plan for future steps. When selecting the next_tool_name and its next_tool_args, ensure the tool is one of:\\n\\n1. **search**: Retrieves abstracts from Wikipedia. It takes arguments {'query': {'type': 'string'}} in JSON format.\\n2. **finish**: Marks the task as complete, signaling that all information for producing the outputs, i.e., `answer`, are now available to be extracted. It takes arguments {} in JSON format.\\n\\nYour goal is to use one or more of the supplied tools to collect any necessary information for producing `answer`. The trajectory, which records all thoughts, tool selections, tool arguments, and observations, is crucial for extracting the final answer. Ensure that each step is meticulously planned and executed to achieve the most accurate and comprehensive response possible.\"\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "print(optimized_react)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "585869ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "react = Predict(StringSignature(question, trajectory -> next_thought, next_tool_name, next_tool_args\n",
      "    instructions=\"Given the fields `question`, produce the fields `answer`.\\n\\nYou are an Agent. In each episode, you will be given the fields `question` as input. And you can see your past trajectory so far.\\nYour goal is to use one or more of the supplied tools to collect any necessary information for producing `answer`.\\n\\nTo do this, you will interleave next_thought, next_tool_name, and next_tool_args in each turn, and also when finishing the task.\\nAfter each tool call, you receive a resulting observation, which gets appended to your trajectory.\\n\\nWhen writing next_thought, you may reason about the current situation and plan for future steps.\\nWhen selecting the next_tool_name and its next_tool_args, the tool must be one of:\\n\\n(1) search, whose description is <desc>Retrieves abstracts from Wikipedia.</desc>. It takes arguments {'query': {'type': 'string'}} in JSON format.\\n(2) finish, whose description is <desc>Marks the task as complete. That is, signals that all information for producing the outputs, i.e. `answer`, are now available to be extracted.</desc>. It takes arguments {} in JSON format.\"\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    next_thought = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Thought:', 'desc': '${next_thought}'})\n",
      "    next_tool_name = Field(annotation=Literal['search', 'finish'] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Name:', 'desc': '${next_tool_name}'})\n",
      "    next_tool_args = Field(annotation=dict[str, Any] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Args:', 'desc': '${next_tool_args}'})\n",
      "))\n",
      "extract.predict = Predict(StringSignature(question, trajectory -> reasoning, answer\n",
      "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "print(react)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
